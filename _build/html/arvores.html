

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>3.2 Árvores de decisão &#8212; Introdução ao reconhecimento de Padrões</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'arvores';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Capítulo 4: Combinação de classificadores" href="combinacao.html" />
    <link rel="prev" title="3.1 Máquinas de vetores de suporte e função kernel" href="kernel.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="introduction.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logobg.png" class="logo__image only-light" alt="Introdução ao reconhecimento de Padrões - Home"/>
    <script>document.write(`<img src="_static/logobg.png" class="logo__image only-dark" alt="Introdução ao reconhecimento de Padrões - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="introduction.html">
                    Apresentação
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="reconhecimento.html">Introdução ao reconhecimento de padrões</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes.html">Capítulo 1: Teoria da decisão de Bayes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="classificadores-lineares.html">Capítulo 2: Classificadores lineares</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="perceptron.html">2.2 Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="estimativa.html">2.3 Estimativa baseada na soma dos erros quadráticos</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm.html">2.4 Máquina de vetores de suporte (SVM) - versão linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiclasse.html">2.5 Estratétegias Multiclasse</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="nao-linear.html">Capítulo 3: Classificadores não lineares</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="kernel.html">3.1 Máquinas de vetores de suporte e função kernel</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">3.2 Árvores de decisão</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="combinacao.html">Capítulo 4: Combinação de classificadores</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="votacao.html">4.1 Votação por maioria e soft voting</a></li>
<li class="toctree-l2"><a class="reference internal" href="stacking.html">4.2 Stacking</a></li>
<li class="toctree-l2"><a class="reference internal" href="floresta.html">4.3 Floresta Aleatória</a></li>
<li class="toctree-l2"><a class="reference internal" href="bagging.html">4.4 Bagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="boosting.html">4.5 Boosting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exemplos.html">Capítulo 5: Exemplos</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Farvores.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/arvores.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>3.2 Árvores de decisão</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <style>
    legend {
        font-size: 16px;
    }
    main {
        text-align: justify;
    }
</style>
<section class="tex2jax_ignore mathjax_ignore" id="arvores-de-decisao">
<h1>3.2 Árvores de decisão<a class="headerlink" href="#arvores-de-decisao" title="Permalink to this heading">#</a></h1>
<p>No contexto da teoria de garfos, uma árvore binária é estruturada através de vértices (ou nós) e relação hierárquicas. Partindo de um nó, usualmente denominando raiz, podem ser definidas ramificações bipartidas sucessivas, as quais determinam novos nós. Um nó é dito interno desde que produza ramificações, caso contrário é denominado folha. A Figura 3.4 ilustra a estrutura discutida.</p>
<div align="center"> 
<p><img alt="figura34" src="_images/figura34.png" /> <legend>Figura 3.4 - Exemplo de árvore de decisão binária.</legend> </div></p>
<p>A estrutura fornecida por este tipo de garfo favoreceu uma abordagem de classificação não linear distinta das discussões anteriores, denominadas árvores de decisão. Em geral, a modelagem de uma árvore de decisão é baseada em verificações sucessivas sobre os atributos dos padrões em um conjunto de treinamento. Tais verificações consistem em determinar um limiar que atuará apenas sobre um dos atributos  dos padrões e, por sua vez, que permite dividir os exemplos em dois subconjuntos cujas respectivas variabilidades são minimizadas. Esse processo é realizado sucessivamente até que subconjuntos gerados apresentem variabilidade inferior a um valor preestabelecido. A Figura 3.5 traz um exemplo de árvore de decisão e a separação proporcionada sobre os dados no espaço de atributo.</p>
<div align="center"> 
<p><img alt="figura35" src="_images/figura35.png" /> <legend>Figura 3.5 - Particionamento efetuado sobre o espaço de atributos pela árvore de decisão.</legend> </div></p>
<p>Entre diferentes propostas existentes na literatura para construção de árvores de decisão aplicadas à classificação de padrões e regressão, as discussões que seguem referem-se ao método denominado CART (<span class="math notranslate nohighlight">\(\textit{Classification and Regression Trees}\)</span>).</p>
<p>Formalmente, partimos de <span class="math notranslate nohighlight">\(D = \{(\textbf{x}_{i},y_{i}) \in  \mathcal{X} × \mathcal{Y}: \ i=1,...m\}\)</span> como conjunto de treinamento, sendo <span class="math notranslate nohighlight">\(\mathcal{X}⊆\mathbb{R}^{n}\)</span> e <span class="math notranslate nohighlight">\(\mathcal{Y}=\{1,...,c\}\)</span>, o qual é relacionado ao conjunto de classes <span class="math notranslate nohighlight">\(\Omega=\{\omega_{1},...\omega_{c}\}\)</span>. Como já empregado, <span class="math notranslate nohighlight">\(y_{i}\)</span> atua como indicador de classe, talque <span class="math notranslate nohighlight">\(y_{i}=j\)</span> implica que que <span class="math notranslate nohighlight">\(\textbf{x}_{i}\)</span> está associado à classe <span class="math notranslate nohighlight">\(\omega_{j}\)</span>.</p>
<p>Conforme evidenciado, ao longo do processo de construção da árvore de decisão, são utilizados subconjuntos <span class="math notranslate nohighlight">\(D\)</span> cada vez mais restritos. A fim de generalizar as notações, será denominado <span class="math notranslate nohighlight">\(Q\)</span> o subconjunto de elementos de <span class="math notranslate nohighlight">\(D\)</span> considerado em um nó desta árvore. Em um primeiro momento, na raiz da árvore, o conjunto <span class="math notranslate nohighlight">\(Q\)</span> equivale a <span class="math notranslate nohighlight">\(D\)</span>.</p>
<p>Assim, para um nó qualquer, <span class="math notranslate nohighlight">\(Q\)</span> é composto por <span class="math notranslate nohighlight">\(q\)</span> pares <span class="math notranslate nohighlight">\((\textbf{x},y)\)</span>. Independentemente do comportamento dos padrões <span class="math notranslate nohighlight">\(\textbf{x}\)</span> em <span class="math notranslate nohighlight">\(Q\)</span> e do atributo considerado, existem, no máximo, <span class="math notranslate nohighlight">\(𝜏\leq q\)</span> valores que permitem a divisão deste conjunto em duas partes. No entanto, devido a possíveis repetições de valores que cada um dos atributos pode apresentar, a quantidade de candidatos a limiar para divisão de <span class="math notranslate nohighlight">\(Q\)</span> pode variar em função dos atributos.</p>
<p>Seja <span class="math notranslate nohighlight">\(Q_{k} = \{x_{k}:(\textbf{x},y)\in Q; \ \textbf{x}=[x_{1},...,x_{k},...,x_{n}]\}\)</span> o conjunto de valore observados, sem separação, sobre o k-ésimo atributo dos exemplos de Q. No contexto desta discussão, podem ser definidos <span class="math notranslate nohighlight">\(𝜏_{kh}\)</span> valores, com <span class="math notranslate nohighlight">\(k=2,...n\)</span> e <span class="math notranslate nohighlight">\(h=1,...,\#Q_{k}\)</span>, que, por sua vez, determinam <span class="math notranslate nohighlight">\(Q_{inf}(𝜏_{kh})\)</span> e <span class="math notranslate nohighlight">\(Q_{sup}(𝜏_{kh})\)</span> como subconjuntos de <span class="math notranslate nohighlight">\(Q\)</span>, cujo valor do k-ésimo atributo de seus vetores <span class="math notranslate nohighlight">\(\textbf{x}\)</span> é inferior ou maior-ou-igual a <span class="math notranslate nohighlight">\(𝜏_{kh}\)</span>, respectivamente. Ou seja:</p>
<div align="center"> 
<p><span class="math notranslate nohighlight">\(\begin{equation}
Q_{inf}(𝜏_{kh}) = \{(\textbf{x},y) \in Q:x_{k} &lt; 𝜏_{kh}\}
\end{equation}\)</span></p>
<p><span class="math notranslate nohighlight">\(\begin{equation}
Q_{sup}(𝜏_{kh}) = \{(\textbf{x},y) \in Q:x_{k} \geq 𝜏_{kh}\}
\end{equation}\)</span> </div></p>
<p>A fim de quantificar a variabilidade de classes em <span class="math notranslate nohighlight">\(Q\)</span>, também denominada impureza, é usual o emprego da medida de Entropia da Informação, expressa na Equação 3.7. Cabe observar que o valor máximo desta medida é atingido quando as probabilidades de ocorrência das classes se tornam iguais. Logo, sua minimização leva à mínima incerteza com que os elementos deste conjunto são associados a uma das classes do problema.</p>
<div align="center"> 
<p><span class="math notranslate nohighlight">\(\begin{equation}
I(Q) = - \sum_{j=1}^{c} P(\omega_{j}|Q)\log_{2}P(\omega_{j}|Q) \tag{3.7}
\end{equation}\)</span></p>
<p>em que:</p>
<p><span class="math notranslate nohighlight">\(\begin{equation}
P(\omega_{j}|Q)=\frac{1}{\#Q} \sum_{i=1}^{\#Q} \delta_{j}(y_{i})
\end{equation}\)</span></p>
<p><span class="math notranslate nohighlight">\(\begin{equation}
\delta_{j}(y_{i}) = \left \{ \begin{matrix} 1; \ se \ y_{i}=j \\ 0; \ caso \ contrário \end{matrix} \right.
\end{equation}\)</span> </div></p>
<p>Dessa forma, diante da escolha de um limiar <span class="math notranslate nohighlight">\(𝜏_{kh}\)</span>, é possível medir a redução da impureza que será proporcionada ao subdividir <span class="math notranslate nohighlight">\(Q\)</span> em <span class="math notranslate nohighlight">\(Q_{inf}(𝜏_{kh})\)</span> e <span class="math notranslate nohighlight">\(Q_{sup}(𝜏_{kh})\)</span>, conforme definido na Equação 3.7. é importante destacar que a determinação de <span class="math notranslate nohighlight">\(𝜏_{kh}\)</span> é alcançada de forma exaustiva com base nos valores de <span class="math notranslate nohighlight">\(Q_{k}\)</span>, para <span class="math notranslate nohighlight">\(k=1,...,n\)</span>.</p>
<div align="center"> 
<p><span class="math notranslate nohighlight">\(\begin{equation}
\Delta I(Q;𝜏_{kh})= I(Q)-\frac{\#Q_{inf}(𝜏_{kh})}{\#Q}I(Q_{inf}(𝜏_{kh}))-\frac{\#Q_{sup}(𝜏_{kh})}{\#Q}I(Q_{sup}(𝜏_{kh})) \tag{3.8}
\end{equation}\)</span> </div></p>
<p>Nestas condições, quando <span class="math notranslate nohighlight">\(\Delta I(Q;𝜏_{kh})\)</span> supera um limiar <span class="math notranslate nohighlight">\(\zeta \in \mathbb{R}_{+}\)</span> preestabelecido e a quantidade de elementos <span class="math notranslate nohighlight">\(Q\)</span> também supera um número mínimo <span class="math notranslate nohighlight">\(\psi \in \mathbb{N}^{*}\)</span>, torna-se justificada a necessidade de divisão entre <span class="math notranslate nohighlight">\(Q_{inf}(𝜏_{kh})\)</span> por <span class="math notranslate nohighlight">\(D_{sup}(𝜏_{kh})\)</span>. Nesse caso, todos os processos discutidos anteriormente são conduzidos em caráter recursivo sobre cada subconjunto obtido, os quais caracterizam novos nós da árvore de decisão em construção e possuem <span class="math notranslate nohighlight">\(Q\)</span> igual a <span class="math notranslate nohighlight">\(Q_{inf}(𝜏_{kh})\)</span> e <span class="math notranslate nohighlight">\(D_{sup}(𝜏_{kh})\)</span>, respectivamente.</p>
<p>Caso a divisão não se justifique, o nó associado ao conjunto (local) <span class="math notranslate nohighlight">\(Q\)</span> é caracterizado como uma “folha” e, por sua vez, deve representar uma das classes <span class="math notranslate nohighlight">\(\omega^{*} \in \Omega\)</span>. Para tal associação, a seguinte regra pode ser empregada:</p>
<div align="center"> 
<p><span class="math notranslate nohighlight">\(\begin{equation}
\omega^{*} = arg\max_{\omega_{j}\in\Omega}P(\omega_{j}|Q) \tag{3.9}
\end{equation}\)</span> </div></p>
<p>Uma vez cessado o crescimento da árvore de decisão, o processo de treinamento é finalizado. Por conseguinte, o processo de classificação de um padrão não rotulado é efetuado a partir de sua apresentação na raiz da árvore de decisão, sendo, então, submetido sequencialmente às diversas regras relacionadas aos nós até que uma folha seja alcançada. A classe representada pela folha em questão determina a classificação do padrão em estudo.</p>
<p>Como exemplo de aplicação, a Figura 3.6 ilustra o comportamento das superfícies  de decisão delineadas pelo método CART sobre a conhecida base de dados Iris, que apresenta um problema multiclasse que possui características lineares e não lineares. O particionamento do espaço de atributos através de limiares constantes em relação aos atributos, similar à concepção da Figura 3.6, proporciona o aspecto de “setores”.</p>
<div align="center"> 
<p><img alt="figura36" src="_images/figura36.png" /> <legend>Figura 3.6 - Exemplo de aplicação do método CART utilizando a base de dados Iris.</legend> </div></p>
<p>A partir da biblioteca Scikit-Learn, com a importação do módulo <span class="math notranslate nohighlight">\(\textbf{tree}\)</span>, a implementação do classificador CART torna-se acessível via <span class="math notranslate nohighlight">\(\textbf{DecisionTreeClassifier}\)</span>. O código 3.2 apresenta apenas o trecho de importação do módulo citado e a instanciação de um classificador CART. O uso das funções de treinamento e predições/classificação é idêntico ao caso do classificador SVM. Os parâmetros <span class="math notranslate nohighlight">\(\textbf{criterion}\)</span>,<span class="math notranslate nohighlight">\(\textbf{min_samples_split}\)</span> e <span class="math notranslate nohighlight">\(\textbf{min_impurity_decrease}\)</span> referem-se ao tipo da medida de impureza e aos parâmetros <span class="math notranslate nohighlight">\(\psi\)</span> e <span class="math notranslate nohighlight">\(\zeta\)</span>, respectivamente. A configuração <span class="math notranslate nohighlight">\(\textbf{criterion='entropy'}\)</span> determina que a construção da árvore de decisão é baseada na medida de entropia.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Código 3.2 - Instanciação do Classificador Árvore de Decisão</span>

<span class="c1">#importação</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>

<span class="c1">#Instanciação do classificador &#39;g&#39;</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span><span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Exemplo 2 - Aplicação do classificador de árvore de decisão ao dataset Iris e plotagem das superfícies de decisão</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="c1"># Parâmetros</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">plot_colors</span> <span class="o">=</span> <span class="s2">&quot;ryb&quot;</span>
<span class="n">plot_step</span> <span class="o">=</span> <span class="mf">0.02</span>


<span class="k">for</span> <span class="n">pairidx</span><span class="p">,</span> <span class="n">pair</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]):</span>
    <span class="c1"># Selecionando os atributos aos pares</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="n">pair</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

    <span class="c1"># Treino</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span><span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">))</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Plotagem da superfície de decisão</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pairidx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">h_pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">w_pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>
    <span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdYlBu</span><span class="p">,</span>
        <span class="n">response_method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
    <span class="p">)</span>

    <span class="c1"># Plotagem dos pontos de treinamento</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span> <span class="n">plot_colors</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdYlBu</span><span class="p">,</span>
            <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
            <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
        <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Superfície de decisão de árvores de decisão treinadas em pares de atributos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">borderpad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">handletextpad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="kernel.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">3.1 Máquinas de vetores de suporte e função kernel</p>
      </div>
    </a>
    <a class="right-next"
       href="combinacao.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Capítulo 4: Combinação de classificadores</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Vitor Jorge
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>